temp.date <- as.Date.character(temp$Group.1)
temp.date
temp.date.character <- as.Date.character(temp$Group.1)
temp.date <- as.Date(temp.date.character, "%Y/%m/%d")
temp.date
class(temp.date)
num.steps.date <- data.frame(temp.date, temp$x)
View(num.steps.date)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
ggplot(data=num.steps.date, aes(x=steps)) +
geom_histogram(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
ggplot(data=num.steps.date, aes(date,steps)) +
geom_histogram(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
ggplot(num.steps.date, aes(date, price)) +
geom_line()
ggplot(num.steps.date, aes(date, steps)) +
geom_line()
ggplot(data=num.steps.date, aes(date,steps)) +
geom_line(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
num.steps.date <- aggregate(subdata$steps, list(subdata$date), sum)
View(num.steps.date)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
head(num.steps.date)
ggplot(data=num.steps.date, aes(date,steps)) +
geom_line(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
ggplot(data=num.steps.date, aes(date,steps)) +
geom_histogram(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
data <- read.csv('data/activity.csv')
head(data)
nrow(data)
subdata = data[!is.na(data$steps), ]
head(subdata)
nrow(data)
temp <- aggregate(subdata$steps, list(subdata$date), sum)
temp.date.character <- as.Date.character(temp$Group.1)
temp.date <- as.Date(temp.date.character, "%Y/%m/%d")
num.steps.date <- data.frame(temp.date, temp$x)
colnames(num.steps.date) <- c("date", "steps")
head(num.steps.date)
ggplot(data=num.steps.date, aes(date,steps)) +
geom_line(fill="#880011") +
ggtitle("Steps Taken per Day") +
labs(x="Number of Steps per Day", y="Number of times in a day")
View(num.steps.date)
subdata$steps
mean(subdata$steps)
temp <- aggregate(subdata$steps, list(subdata$date), mean )
View(temp)
subdata
a <- subdata[subdata$date="2012-10-02"]
a <- subdata[subdata$date="2012-10-02",]
a <- subdata[subdata$date=="2012-10-02",]
a
mean(a)
mean(a$steps)
nrow(a$steps)
nrow(a)
install.packages("magick")
install.packages("magick", dependencies = TRUE)
library(magick)
x <- image_read("/home/pc/train/00087a6bd4dc_01.jpg")
x
image_info(x)
y <- image_border(x, "red", "20x10")
getwd()
y
image_scale(x, 400)
image_scale(x, "400")
z <- image_scale(x, "400")
image_background(z, "blue", flatten = FALSE)
z1 <- image_background(z, "blue", flatten = FALSE)
z1
z1 <- image_background(z, "blue", flatten = TRUE)
z1
image_flatten(z1, "Add")
image_flatten(z1, 'Add')
image_write(z1, path = tiff_file, format = 'tiff')
tiff_file <- tempfile()
image_write(z1, path = tiff_file, format = 'tiff')
r <- raster::brick(tiff_file)
r <- raster::brick(z1)
image_fill(z1, "blue", point = "+100+200", fuzz = 30000))
image_fill(z1, "blue", point = "+100+200", fuzz = 30000)
image_fill(z1, "black", point = "+100+200", fuzz = 30000)
image_fill(z1, "black", point = "+100+200", fuzz = 10000)
image_fill(z1, "white", point = "+100+200", fuzz = 10000)
image_fill(z1, "white", point = "+100+200", fuzz = 20000)
image_fill(z1, "white", point = "+100+200", fuzz = 30000)
image_fill(z1, "white", point = "+100+200", fuzz = 1000)
image_fill(z1, "blue", "+100+200")
image_fill(z1, "white", point = "+100+200", fuzz = 1000)
image_fill(z1, "blue", "+100+200")
image_fill(z1, "white", point = "+100+200", fuzz = 1000)
image_fill(z1, "blue", "+100+200")
image_fill(z1, "white", "+100+200000")
image_fill(z1, "white", "+900+800")
image_fill(z1, "white", "+900+800")
image_average(z1)
image_chop(z1,geometry = point)
image_chop(z1)
image_device(width = 600, height = 600, bg = "transparent",
pointsize = 12, res = 72, clip = TRUE)
image_noise(z1)
image_noise(z1)
image_device(width = 600, height = 600, bg = "transparent",
pointsize = 12, res = 72, clip = TRUE)
image_noise(z1)
image_noise(z1)
image_noise(z1)
image_noise(z1)
image_edge(z1)
z1
image_oilpaint(z1)
image_emboss(z1)
image_emboss(z1)
z2 <- image_emboss(z1)
z2 <- image_emboss(z2)
image_emboss(z2)
image_emboss(z1)
image_enhance(z1)
image_equalize(z1)
image_fill(image_flatten(z1), "red")
image_fill(image_flatten(z1), "red")
View(temp)
load.data.file <- function(arg) {
con <- file(arg,open="r")
line <- readLines(con, skipNul = TRUE)
close(con)
line
}
porcentaje.data.file <- function(arg, valor) {
tmp <- sample(arg, size = length(arg) * valor)
tmp
}
file1 <- load.data.file("final/en_US/en_US.blogs.txt")
file2 <- load.data.file("final/en_US/en_US.news.txt")
file3 <- load.data.file("final/en_US/en_US.twitter.txt")
file1.percent <- porcentaje.data.file(file1, 0.01)
file2.percent <- porcentaje.data.file(file2, 0.01)
file3.percent<- porcentaje.data.file(file3, 0.01)
library("tm")
#This SnowballC package contains a method to reduce a word to its root.
library("SnowballC")
#Wordcloud package is useful for creating a word cloud
library("wordcloud")
library("RColorBrewer")
files.percent <- VectorSource(c(file1.percent, file2.percent, file3.percent))
corpus <- Corpus(files.percent)
corpus <- tm_map(corpus, tolower)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stripWhitespace)
summary(corpus)
corpus
tdm <- TermDocumentMatrix(corpus)
m <- as.matrix(tdm)
exit
quit()
install.packages("sparklyr")
library(sparklyr)
sc <- spark_connect(master = "local")
sdf_len(sc, 5, repartition = 1) %>%
spark_apply(function(e) I(e))
getwd()
if(!file.exists("2008.csv.bz2"))
{download.file("http://stat-computing.org/dataexpo/2009/2008.csv.bz2", "2008.csv.bz2")}
spark_read_csv(sc, "flights_spark_2008", "2008.csv.bz2", memory = FALSE)
flights_table <- tbl(sc,"flights_spark_2008") %>%
mutate(DepDelay = as.numeric(DepDelay),
ArrDelay = as.numeric(ArrDelay),
DepDelay > 15 , DepDelay < 240,
ArrDelay > -60 , ArrDelay < 360,
Gain = DepDelay - ArrDelay) %>%
filter(ArrDelay > 0) %>%
select(Origin, Dest, UniqueCarrier, Distance, DepDelay, ArrDelay, Gain)
library(dplyr)
library(ggplot2)
flights_table <- tbl(sc,"flights_spark_2008") %>%
mutate(DepDelay = as.numeric(DepDelay),
ArrDelay = as.numeric(ArrDelay),
DepDelay > 15 , DepDelay < 240,
ArrDelay > -60 , ArrDelay < 360,
Gain = DepDelay - ArrDelay) %>%
filter(ArrDelay > 0) %>%
select(Origin, Dest, UniqueCarrier, Distance, DepDelay, ArrDelay, Gain)
View(data)
sdf_register(flights_table, "flights_spark")
tbl_cache(sc, "flights_spark")
library(sparklyr)
library(dplyr)
library(ggplot2)
conf <- spark_config()
sc <- spark_connect(master = "local")
spark_read_csv(sc, "flights_spark_2008", "2008.csv.bz2", memory = FALSE)
flights_table <- tbl(sc,"flights_spark_2008") %>%
mutate(DepDelay = as.numeric(DepDelay),
ArrDelay = as.numeric(ArrDelay),
DepDelay > 15 , DepDelay < 240,
ArrDelay > -60 , ArrDelay < 360,
Gain = DepDelay - ArrDelay) %>%
filter(ArrDelay > 0) %>%
select(Origin, Dest, UniqueCarrier, Distance, DepDelay, ArrDelay, Gain)
flights_table
class(flights_table)
sdf_register(flights_table, "flights_spark")
tbl_cache(sc, "flights_spark")
setwd("GettingCleaning/")
getwd()
list.files()
file.zip<-"getdata_projectfiles_UCI HAR Dataset.zip
))
")"
unzip("getdata_projectfiles_UCI HAR Dataset.zip")
list.files("UCI HAR Dataset/")
list.files()
list.files("UCI HAR Dataset/")
list.files("UCI HAR Dataset/")
"UCI HAR Dataset/train/X_train.txt"
dataSubjectTrain <- read.table("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
dataSubjectTest  <- read.table("UCI HAR Dataset/test/subject_test.txt",header = FALSE)
View(dataSubjectTrain)
View(dataSubjectTest)
View(dataSubjectTrain)
View(dataSubjectTest)
dataActivityTest  <- read.table("dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("dataset/train/y_train.txt",header = FALSE)
dataActivityTest  <- read.table("UCI HAR Dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("UCI HAR Dataset/train/y_train.txt",header = FALSE)
dataFeaturesTest  <- read.table("UCI HAR Dataset/test/X_test.txt",header = FALSE)
dataFeaturesTrain <- read.table("UCI HAR Dataset/train/X_train.txt",header = FALSE)
View(dataFeaturesTrain)
View(dataFeaturesTest)
View(dataSubjectTrain)
View(dataSubjectTest)
View(dataActivityTrain)
dataSubjectTrain <- data.frame("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
dataSubjectTrain <- data.frame("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
View(dataSubjectTrain)
dataSubjectTrain <- read.table("dataset/train/subject_train.txt",header = FALSE)
dataSubjectTest  <- read.table("dataset/test/subject_test.txt",header = FALSE)
dataActivityTest  <- read.table("dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("dataset/train/y_train.txt",header = FALSE)
dataFeaturesTest  <- read.table("dataset/test/X_test.txt",header = FALSE)
dataFeaturesTrain <- read.table("dataset/train/X_train.txt",header = FALSE)
dataSubjectTrain <- read.table("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
dataSubjectTest  <- read.table("UCI HAR Dataset/test/subject_test.txt",header = FALSE)
dataActivityTest  <- read.table("UCI HAR Dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("UCI HAR Dataset/train/y_train.txt",header = FALSE)
dataFeaturesTest  <- read.table("UCI HAR Dataset/test/X_test.txt",header = FALSE)
dataFeaturesTrain <- read.table("UCI HAR Dataset/train/X_train.txt",header = FALSE)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
View(dataActivity)
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
View(dataSubject)
View(dataActivity)
colnames(dataSubject) <- "subject"
colnames(dataActivity) <- "activity"
View(dataFeatures)
dataFeaturesNames <- read.table("dataset/features.txt",head=FALSE)
dataFeaturesNames <- read.table("UCI HAR Dataset/features.txt",head=FALSE)
View(dataFeaturesNames)
colnames(dataFeatures) <- dataFeaturesNames$V2
mergeColData <- cbind(dataFeatures,dataActivity,dataSubject)
View(mergeColData)
list.files()
list.files("UCI HAR Dataset/")
dataSubjectTrain <- read.table("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
dataSubjectTest  <- read.table("UCI HAR Dataset/test/subject_test.txt",header = FALSE)
dataActivityTest  <- read.table("UCI HAR Dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("UCI HAR Dataset/train/y_train.txt",header = FALSE)
dataFeaturesTest  <- read.table("UCI HAR Dataset/test/X_test.txt",header = FALSE)
dataFeaturesTrain <- read.table("UCI HAR Dataset/train/X_train.txt",header = FALSE)
head(dataSubjectTrain)
head(dataActivityTrain)
head(dataFeaturesTrain)
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
colnames(dataSubject) <- "subject"
colnames(dataActivity) <- "activity"
dataFeaturesNames <- read.table("UCI HAR Dataset/features.txt",head=FALSE)
colnames(dataFeatures) <- dataFeaturesNames$V2
mergeColData <- cbind(dataFeatures,dataActivity,dataSubject)
print("******2. Extracts only the measurements on the mean and standard deviation for each measurement *****")
#We load only the columns that have mean y std
colWithMeanSTD <- grep(".*mean.*|.*std.*", names(mergeColData), ignore.case=TRUE)
requiredColumns <- c(colWithMeanSTD, 562, 563)
extractedData <- mergeColData[,requiredColumns]
#dim(extractedData)
print("******3. Uses descriptive activity names to name the activities in the data set ******")
#We change the numerical value of "activity" column by its description, example 5 = STANDING
activityLabels <- read.table("dataset/activity_labels.txt",header = FALSE)
#head(activityLabels$V2[extractedData$activity],30)
summary(dataFeaturesTrain)
dataFeaturesTrain(1:50)
dataFeaturesTrain(1:50,)
dataFeaturesTrain(c(1:50),)
dataFeaturesTrain[c(1:50),]
dataFeaturesTrain[c(1:5),]
dataFeaturesTrain[c(1:5),c(1:7)]
#####################################################################
# Peer-graded Assignment: Getting and Cleaning Data Course Project
# getting-and-cleaning-data
# Marco Guado Zavaleta, mguado@gmail.com
# 2016
#####################################################################
#run console, example:
#>executeAnalysis()
executeAnalysis <- function() {
#1. Merges the training and the test sets to create one data set.
#
# Folder structure and files.
# >dir()
# >dataset/test/subject_test.txt
# >dataset/test/X_test.txt
# >dataset/test/y_test.txt
# >dataset/train/subject_train.txt
# >dataset/train/X_train.txt
# >dataset/train/y_train.txt
#
# load data
print("****** 1. Merges the training and the test sets to create one data set ****")
dataSubjectTrain <- read.table("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
dataSubjectTest  <- read.table("UCI HAR Dataset/test/subject_test.txt",header = FALSE)
dataActivityTest  <- read.table("UCI HAR Dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("UCI HAR Dataset/train/y_train.txt",header = FALSE)
dataFeaturesTest  <- read.table("UCI HAR Dataset/test/X_test.txt",header = FALSE)
dataFeaturesTrain <- read.table("UCI HAR Dataset/train/X_train.txt",header = FALSE)
#Merge subject, train and test
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
#add title head
colnames(dataSubject) <- "subject"
colnames(dataActivity) <- "activity"
dataFeaturesNames <- read.table("UCI HAR Dataset</features.txt",head=FALSE)
colnames(dataFeatures) <- dataFeaturesNames$V2
mergeColData <- cbind(dataFeatures,dataActivity,dataSubject)
print("******2. Extracts only the measurements on the mean and standard deviation for each measurement *****")
#We load only the columns that have mean y std
colWithMeanSTD <- grep(".*mean.*|.*std.*", names(mergeColData), ignore.case=TRUE)
requiredColumns <- c(colWithMeanSTD, 562, 563)
extractedData <- mergeColData[,requiredColumns]
#dim(extractedData)
print("******3. Uses descriptive activity names to name the activities in the data set ******")
#We change the numerical value of "activity" column by its description, example 5 = STANDING
activityLabels <- read.table("UCI HAR Dataset</activity_labels.txt",header = FALSE)
#head(activityLabels$V2[extractedData$activity],30)
extractedData$activity <- head(activityLabels$V2[extractedData$activity],length(extractedData$activity))
print("*****4. Appropriately labels the data set with descriptive variable names. ****")
#We change the letter that is in each column for each description, example t = time
names(extractedData)<-gsub("^t", "time", names(extractedData))
names(extractedData)<-gsub("^f", "frequency", names(extractedData))
names(extractedData)<-gsub("Acc", "Accelerometer", names(extractedData))
names(extractedData)<-gsub("Gyro", "Gyroscope", names(extractedData))
names(extractedData)<-gsub("Mag", "Magnitude", names(extractedData))
names(extractedData)<-gsub("BodyBody", "Body", names(extractedData))
names(extractedData)
print("********5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.*******")
#We create a data set ordered subject
Data<-aggregate(. ~subject + activity, extractedData, mean)
Data<-Data[order(Data$subject,Data$activity),]
write.table(Data, file = "newdata_temp.txt",row.name=FALSE)
}
executeAnalysis()
#####################################################################
# Peer-graded Assignment: Getting and Cleaning Data Course Project
# getting-and-cleaning-data
# Marco Guado Zavaleta, mguado@gmail.com
# 2016
#####################################################################
#run console, example:
#>executeAnalysis()
executeAnalysis <- function() {
#1. Merges the training and the test sets to create one data set.
#
# Folder structure and files.
# >dir()
# >dataset/test/subject_test.txt
# >dataset/test/X_test.txt
# >dataset/test/y_test.txt
# >dataset/train/subject_train.txt
# >dataset/train/X_train.txt
# >dataset/train/y_train.txt
#
# load data
print("****** 1. Merges the training and the test sets to create one data set ****")
dataSubjectTrain <- read.table("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
dataSubjectTest  <- read.table("UCI HAR Dataset/test/subject_test.txt",header = FALSE)
dataActivityTest  <- read.table("UCI HAR Dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("UCI HAR Dataset/train/y_train.txt",header = FALSE)
dataFeaturesTest  <- read.table("UCI HAR Dataset/test/X_test.txt",header = FALSE)
dataFeaturesTrain <- read.table("UCI HAR Dataset/train/X_train.txt",header = FALSE)
#Merge subject, train and test
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
#add title head
colnames(dataSubject) <- "subject"
colnames(dataActivity) <- "activity"
dataFeaturesNames <- read.table("UCI HAR Dataset/features.txt",head=FALSE)
colnames(dataFeatures) <- dataFeaturesNames$V2
mergeColData <- cbind(dataFeatures,dataActivity,dataSubject)
print("******2. Extracts only the measurements on the mean and standard deviation for each measurement *****")
#We load only the columns that have mean y std
colWithMeanSTD <- grep(".*mean.*|.*std.*", names(mergeColData), ignore.case=TRUE)
requiredColumns <- c(colWithMeanSTD, 562, 563)
extractedData <- mergeColData[,requiredColumns]
#dim(extractedData)
print("******3. Uses descriptive activity names to name the activities in the data set ******")
#We change the numerical value of "activity" column by its description, example 5 = STANDING
activityLabels <- read.table("UCI HAR Dataset</activity_labels.txt",header = FALSE)
#head(activityLabels$V2[extractedData$activity],30)
extractedData$activity <- head(activityLabels$V2[extractedData$activity],length(extractedData$activity))
print("*****4. Appropriately labels the data set with descriptive variable names. ****")
#We change the letter that is in each column for each description, example t = time
names(extractedData)<-gsub("^t", "time", names(extractedData))
names(extractedData)<-gsub("^f", "frequency", names(extractedData))
names(extractedData)<-gsub("Acc", "Accelerometer", names(extractedData))
names(extractedData)<-gsub("Gyro", "Gyroscope", names(extractedData))
names(extractedData)<-gsub("Mag", "Magnitude", names(extractedData))
names(extractedData)<-gsub("BodyBody", "Body", names(extractedData))
names(extractedData)
print("********5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.*******")
#We create a data set ordered subject
Data<-aggregate(. ~subject + activity, extractedData, mean)
Data<-Data[order(Data$subject,Data$activity),]
write.table(Data, file = "newdata_temp.txt",row.name=FALSE)
}
executeAnalysis()
#####################################################################
# Peer-graded Assignment: Getting and Cleaning Data Course Project
# getting-and-cleaning-data
# Marco Guado Zavaleta, mguado@gmail.com
# 2016
#####################################################################
#run console, example:
#>executeAnalysis()
executeAnalysis <- function() {
#1. Merges the training and the test sets to create one data set.
#
# Folder structure and files.
# >dir()
# >dataset/test/subject_test.txt
# >dataset/test/X_test.txt
# >dataset/test/y_test.txt
# >dataset/train/subject_train.txt
# >dataset/train/X_train.txt
# >dataset/train/y_train.txt
#
# load data
print("****** 1. Merges the training and the test sets to create one data set ****")
dataSubjectTrain <- read.table("UCI HAR Dataset/train/subject_train.txt",header = FALSE)
dataSubjectTest  <- read.table("UCI HAR Dataset/test/subject_test.txt",header = FALSE)
dataActivityTest  <- read.table("UCI HAR Dataset/test/y_test.txt",header = FALSE)
dataActivityTrain <- read.table("UCI HAR Dataset/train/y_train.txt",header = FALSE)
dataFeaturesTest  <- read.table("UCI HAR Dataset/test/X_test.txt",header = FALSE)
dataFeaturesTrain <- read.table("UCI HAR Dataset/train/X_train.txt",header = FALSE)
#Merge subject, train and test
dataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
dataActivity<- rbind(dataActivityTrain, dataActivityTest)
dataFeatures<- rbind(dataFeaturesTrain, dataFeaturesTest)
#add title head
colnames(dataSubject) <- "subject"
colnames(dataActivity) <- "activity"
dataFeaturesNames <- read.table("UCI HAR Dataset/features.txt",head=FALSE)
colnames(dataFeatures) <- dataFeaturesNames$V2
mergeColData <- cbind(dataFeatures,dataActivity,dataSubject)
print("******2. Extracts only the measurements on the mean and standard deviation for each measurement *****")
#We load only the columns that have mean y std
colWithMeanSTD <- grep(".*mean.*|.*std.*", names(mergeColData), ignore.case=TRUE)
requiredColumns <- c(colWithMeanSTD, 562, 563)
extractedData <- mergeColData[,requiredColumns]
#dim(extractedData)
print("******3. Uses descriptive activity names to name the activities in the data set ******")
#We change the numerical value of "activity" column by its description, example 5 = STANDING
activityLabels <- read.table("UCI HAR Dataset/activity_labels.txt",header = FALSE)
#head(activityLabels$V2[extractedData$activity],30)
extractedData$activity <- head(activityLabels$V2[extractedData$activity],length(extractedData$activity))
print("*****4. Appropriately labels the data set with descriptive variable names. ****")
#We change the letter that is in each column for each description, example t = time
names(extractedData)<-gsub("^t", "time", names(extractedData))
names(extractedData)<-gsub("^f", "frequency", names(extractedData))
names(extractedData)<-gsub("Acc", "Accelerometer", names(extractedData))
names(extractedData)<-gsub("Gyro", "Gyroscope", names(extractedData))
names(extractedData)<-gsub("Mag", "Magnitude", names(extractedData))
names(extractedData)<-gsub("BodyBody", "Body", names(extractedData))
names(extractedData)
print("********5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.*******")
#We create a data set ordered subject
Data<-aggregate(. ~subject + activity, extractedData, mean)
Data<-Data[order(Data$subject,Data$activity),]
write.table(Data, file = "newdata_temp.txt",row.name=FALSE)
}
executeAnalysis()
